{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37091,
     "status": "ok",
     "timestamp": 1551957759929,
     "user": {
      "displayName": "qingqing mm",
      "photoUrl": "",
      "userId": "16115205609766247720"
     },
     "user_tz": -480
    },
    "id": "CBNiFf0NjyG2",
    "outputId": "d0c01e82-a4a8-45ca-d7b4-a2173f940929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zY-872yzc-3C"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mUMPoHIdVs9"
   },
   "outputs": [],
   "source": [
    "# set data path\n",
    "base_dir = \"drive/My Drive/Colab Notebooks/\"\n",
    "bottleneck_dir = os.path.join(base_dir, 'bottleneck')\n",
    "xcept_bottleneck_dir = os.path.join(bottleneck_dir, 'xcept')\n",
    "incept_bottleneck_dir = os.path.join(bottleneck_dir, 'incept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfj7Ml-cF_NP"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(base_dir + 'train.csv')\n",
    "\n",
    "train_labels = train_df['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1100,
     "status": "ok",
     "timestamp": 1551776534867,
     "user": {
      "displayName": "qingqing mm",
      "photoUrl": "",
      "userId": "16115205609766247720"
     },
     "user_tz": -480
    },
    "id": "a6n3WpAIg867",
    "outputId": "af446029-966a-48c7-96bf-369573f2166a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tk9L5zKKdtL6"
   },
   "source": [
    "从网络下载training图片。下面是真正的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1884,
     "status": "ok",
     "timestamp": 1551957778564,
     "user": {
      "displayName": "qingqing mm",
      "photoUrl": "",
      "userId": "16115205609766247720"
     },
     "user_tz": -480
    },
    "id": "uTFz4HmOIspz",
    "outputId": "55b32878-7968-419c-d95e-3a3c169500cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D,Dropout,Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fXcaDXmBzbhU"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_callbacks(name_weights, patience_lr):\n",
    "    path = name_weights\n",
    "    mcp_save = ModelCheckpoint(name_weights,save_best_only=True, \n",
    "                               monitor='val_loss', mode='min')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, \n",
    "                                  patience=patience_lr, verbose=1,\n",
    "                                 min_delta=1e-4, mode='min')\n",
    "    return [mcp_save,reduce_lr]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-sj-1TeZYCN7"
   },
   "outputs": [],
   "source": [
    "def save_result(name,predictions,ids=[]):\n",
    "  result = pd.DataFrame({'label': np.squeeze(predictions)})\n",
    "  if len(ids)==0:\n",
    "    result['id'] = pd.Series(range(1,len(predictions)+1),index=range(len(predictions)))\n",
    "  else:\n",
    "    result['id'] = pd.Series(ids,index=range(len(predictions)))\n",
    "  result.to_csv(name,index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1251,
     "status": "ok",
     "timestamp": 1551963120341,
     "user": {
      "displayName": "qingqing mm",
      "photoUrl": "",
      "userId": "16115205609766247720"
     },
     "user_tz": -480
    },
    "id": "hTbTiHj0PbYY",
    "outputId": "ead9b4a7-8de9-4481-c74a-b7b599bc44be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 12500\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(open(xcept_bottleneck_dir+'/train.npy','rb'))\n",
    "test_data = np.load(open(xcept_bottleneck_dir+'/test.npy','rb'))\n",
    "\n",
    "\n",
    "print(len(train_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1459,
     "status": "ok",
     "timestamp": 1551411392172,
     "user": {
      "displayName": "qingqing mm",
      "photoUrl": "",
      "userId": "16115205609766247720"
     },
     "user_tz": -480
    },
    "id": "PVouLMP85VDe",
    "outputId": "1a7f46a0-3fc0-4ea2-848b-f0201c83420b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sV7vkfqLV9fY"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(train_data,train_labels,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4108
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87860,
     "status": "ok",
     "timestamp": 1551777079517,
     "user": {
      "displayName": "qingqing mm",
      "photoUrl": "",
      "userId": "16115205609766247720"
     },
     "user_tz": -480
    },
    "id": "ykwUu4tOHC__",
    "outputId": "0e1f6fb6-b57a-4d1e-dc79-a8469a952ebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "20000/20000 [==============================] - 1s 52us/step - loss: 0.1272 - acc: 0.9751 - val_loss: 0.0422 - val_acc: 0.9916\n",
      "Epoch 2/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0377 - acc: 0.9918 - val_loss: 0.0295 - val_acc: 0.9920\n",
      "Epoch 3/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0293 - acc: 0.9928 - val_loss: 0.0258 - val_acc: 0.9924\n",
      "Epoch 4/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0255 - acc: 0.9929 - val_loss: 0.0234 - val_acc: 0.9928\n",
      "Epoch 5/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0229 - acc: 0.9936 - val_loss: 0.0227 - val_acc: 0.9924\n",
      "Epoch 6/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0212 - acc: 0.9940 - val_loss: 0.0218 - val_acc: 0.9928\n",
      "Epoch 7/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0209 - acc: 0.9934 - val_loss: 0.0214 - val_acc: 0.9930\n",
      "Epoch 8/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0198 - acc: 0.9933 - val_loss: 0.0210 - val_acc: 0.9928\n",
      "Epoch 9/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0192 - acc: 0.9942 - val_loss: 0.0208 - val_acc: 0.9932\n",
      "Epoch 10/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0181 - acc: 0.9943 - val_loss: 0.0214 - val_acc: 0.9926\n",
      "Epoch 11/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0184 - acc: 0.9945 - val_loss: 0.0209 - val_acc: 0.9936\n",
      "Epoch 12/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0170 - acc: 0.9947 - val_loss: 0.0211 - val_acc: 0.9936\n",
      "Epoch 13/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0167 - acc: 0.9948 - val_loss: 0.0208 - val_acc: 0.9930\n",
      "Epoch 14/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0169 - acc: 0.9946 - val_loss: 0.0209 - val_acc: 0.9930\n",
      "Epoch 15/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0165 - acc: 0.9952 - val_loss: 0.0211 - val_acc: 0.9934\n",
      "Epoch 16/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0170 - acc: 0.9945 - val_loss: 0.0211 - val_acc: 0.9934\n",
      "Epoch 17/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0150 - acc: 0.9950 - val_loss: 0.0221 - val_acc: 0.9934\n",
      "Epoch 18/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0167 - acc: 0.9943 - val_loss: 0.0221 - val_acc: 0.9934\n",
      "Epoch 19/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0159 - acc: 0.9951 - val_loss: 0.0216 - val_acc: 0.9934\n",
      "Epoch 20/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0214 - val_acc: 0.9934\n",
      "Epoch 21/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0141 - acc: 0.9956 - val_loss: 0.0215 - val_acc: 0.9934\n",
      "Epoch 22/100\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.0151 - acc: 0.9947 - val_loss: 0.0216 - val_acc: 0.9936\n",
      "Epoch 23/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0147 - acc: 0.9957 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 24/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0144 - acc: 0.9951 - val_loss: 0.0222 - val_acc: 0.9934\n",
      "Epoch 25/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0147 - acc: 0.9952 - val_loss: 0.0219 - val_acc: 0.9936\n",
      "Epoch 26/100\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.0141 - acc: 0.9954 - val_loss: 0.0220 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 27/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0136 - acc: 0.9955 - val_loss: 0.0220 - val_acc: 0.9934\n",
      "Epoch 28/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0146 - acc: 0.9948 - val_loss: 0.0219 - val_acc: 0.9932\n",
      "Epoch 29/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0140 - acc: 0.9951 - val_loss: 0.0219 - val_acc: 0.9932\n",
      "Epoch 30/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0134 - acc: 0.9956 - val_loss: 0.0222 - val_acc: 0.9932\n",
      "Epoch 31/100\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.0131 - acc: 0.9961 - val_loss: 0.0223 - val_acc: 0.9930\n",
      "Epoch 32/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0132 - acc: 0.9954 - val_loss: 0.0222 - val_acc: 0.9932\n",
      "Epoch 33/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0143 - acc: 0.9953 - val_loss: 0.0222 - val_acc: 0.9932\n",
      "Epoch 34/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0137 - acc: 0.9956 - val_loss: 0.0222 - val_acc: 0.9930\n",
      "Epoch 35/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0133 - acc: 0.9959 - val_loss: 0.0221 - val_acc: 0.9932\n",
      "Epoch 36/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0126 - acc: 0.9962 - val_loss: 0.0221 - val_acc: 0.9928\n",
      "Epoch 37/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0137 - acc: 0.9956 - val_loss: 0.0221 - val_acc: 0.9932\n",
      "Epoch 38/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0130 - acc: 0.9962 - val_loss: 0.0221 - val_acc: 0.9934\n",
      "Epoch 39/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0130 - acc: 0.9960 - val_loss: 0.0222 - val_acc: 0.9932\n",
      "Epoch 40/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0119 - acc: 0.9963 - val_loss: 0.0220 - val_acc: 0.9934\n",
      "Epoch 41/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0136 - acc: 0.9958 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 42/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0130 - acc: 0.9954 - val_loss: 0.0221 - val_acc: 0.9934\n",
      "Epoch 43/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0138 - acc: 0.9952 - val_loss: 0.0220 - val_acc: 0.9934\n",
      "Epoch 44/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0126 - acc: 0.9960 - val_loss: 0.0222 - val_acc: 0.9932\n",
      "Epoch 45/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0120 - acc: 0.9963 - val_loss: 0.0221 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 46/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0131 - acc: 0.9955 - val_loss: 0.0221 - val_acc: 0.9930\n",
      "Epoch 47/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0132 - acc: 0.9959 - val_loss: 0.0220 - val_acc: 0.9934\n",
      "Epoch 48/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0131 - acc: 0.9960 - val_loss: 0.0220 - val_acc: 0.9934\n",
      "Epoch 49/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0127 - acc: 0.9958 - val_loss: 0.0219 - val_acc: 0.9934\n",
      "Epoch 50/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0127 - acc: 0.9962 - val_loss: 0.0220 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 51/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0125 - acc: 0.9956 - val_loss: 0.0219 - val_acc: 0.9934\n",
      "Epoch 52/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.0221 - val_acc: 0.9932\n",
      "Epoch 53/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.0221 - val_acc: 0.9932\n",
      "Epoch 54/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0120 - acc: 0.9962 - val_loss: 0.0220 - val_acc: 0.9934\n",
      "Epoch 55/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0137 - acc: 0.9957 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 56/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0120 - acc: 0.9961 - val_loss: 0.0220 - val_acc: 0.9934\n",
      "Epoch 57/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0129 - acc: 0.9958 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 58/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0125 - acc: 0.9959 - val_loss: 0.0220 - val_acc: 0.9934\n",
      "Epoch 59/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0123 - acc: 0.9957 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 60/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0124 - acc: 0.9962 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 61/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0123 - acc: 0.9964 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 62/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0124 - acc: 0.9959 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 63/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0113 - acc: 0.9964 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 64/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0143 - acc: 0.9954 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 65/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0118 - acc: 0.9963 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 66/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0120 - acc: 0.9958 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 67/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0117 - acc: 0.9966 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 68/100\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.0119 - acc: 0.9968 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 69/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0126 - acc: 0.9961 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 70/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0130 - acc: 0.9955 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 71/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 72/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0125 - acc: 0.9957 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 73/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0121 - acc: 0.9959 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 74/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 75/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0115 - acc: 0.9965 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 76/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0123 - acc: 0.9961 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 77/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0121 - acc: 0.9959 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 78/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0126 - acc: 0.9962 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 79/100\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.0138 - acc: 0.9954 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 80/100\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.0127 - acc: 0.9954 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 81/100\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.0126 - acc: 0.9958 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 82/100\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.0134 - acc: 0.9953 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 83/100\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.0127 - acc: 0.9955 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 84/100\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.0121 - acc: 0.9960 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 85/100\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.0125 - acc: 0.9960 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 86/100\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.0130 - acc: 0.9957 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 87/100\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.0124 - acc: 0.9961 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 88/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0123 - acc: 0.9963 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 89/100\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.0124 - acc: 0.9956 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 90/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0123 - acc: 0.9959 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 91/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0130 - acc: 0.9953 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 92/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0117 - acc: 0.9964 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 93/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0123 - acc: 0.9959 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 94/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0119 - acc: 0.9959 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 95/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 96/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0130 - acc: 0.9961 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 97/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0126 - acc: 0.9962 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 98/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0131 - acc: 0.9956 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 99/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0116 - acc: 0.9960 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 100/100\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.0115 - acc: 0.9964 - val_loss: 0.0220 - val_acc: 0.9932\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#train\n",
    "BATCH_SIZE = 100\n",
    "weight_path = base_dir + 'weights/2/' #save to drive\n",
    "\n",
    "train_pred_1 = np.zeros(train_df.shape[0])\n",
    "test_pred_1 = np.zeros(len(test_data))\n",
    "                       \n",
    "            \n",
    "name_weights_1 = os.path.join(weight_path,'best_model_1_weights.h5')\n",
    "callbacks = get_callbacks(name_weights_1,patience_lr=5)                  \n",
    "\n",
    "history = model.fit(train_X,train_y,\n",
    "                    epochs=100,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_data=(val_X, val_y),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "le-2NoPrzWdt"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "adam = optimizers.Adam(lr=0.0005, decay=1e-6)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1910
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33015,
     "status": "ok",
     "timestamp": 1551963298245,
     "user": {
      "displayName": "qingqing mm",
      "photoUrl": "",
      "userId": "16115205609766247720"
     },
     "user_tz": -480
    },
    "id": "3IPgMjoKzlnP",
    "outputId": "4483b672-2f30-4827-d2e9-8619a4068273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.3014 - acc: 0.9303 - val_loss: 0.1235 - val_acc: 0.9882\n",
      "Epoch 2/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0953 - acc: 0.9884 - val_loss: 0.0685 - val_acc: 0.9914\n",
      "Epoch 3/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0631 - acc: 0.9900 - val_loss: 0.0503 - val_acc: 0.9918\n",
      "Epoch 4/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0492 - acc: 0.9906 - val_loss: 0.0410 - val_acc: 0.9918\n",
      "Epoch 5/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0416 - acc: 0.9917 - val_loss: 0.0358 - val_acc: 0.9918\n",
      "Epoch 6/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0372 - acc: 0.9914 - val_loss: 0.0323 - val_acc: 0.9922\n",
      "Epoch 7/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0336 - acc: 0.9919 - val_loss: 0.0301 - val_acc: 0.9922\n",
      "Epoch 8/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0314 - acc: 0.9923 - val_loss: 0.0283 - val_acc: 0.9924\n",
      "Epoch 9/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0289 - acc: 0.9923 - val_loss: 0.0270 - val_acc: 0.9922\n",
      "Epoch 10/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0272 - acc: 0.9928 - val_loss: 0.0259 - val_acc: 0.9926\n",
      "Epoch 11/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0261 - acc: 0.9931 - val_loss: 0.0251 - val_acc: 0.9928\n",
      "Epoch 12/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0255 - acc: 0.9934 - val_loss: 0.0243 - val_acc: 0.9928\n",
      "Epoch 13/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0237 - acc: 0.9938 - val_loss: 0.0238 - val_acc: 0.9928\n",
      "Epoch 14/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0239 - acc: 0.9933 - val_loss: 0.0234 - val_acc: 0.9928\n",
      "Epoch 15/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0233 - acc: 0.9929 - val_loss: 0.0230 - val_acc: 0.9928\n",
      "Epoch 16/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0230 - acc: 0.9934 - val_loss: 0.0227 - val_acc: 0.9930\n",
      "Epoch 17/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0222 - acc: 0.9934 - val_loss: 0.0224 - val_acc: 0.9928\n",
      "Epoch 18/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0220 - acc: 0.9936 - val_loss: 0.0223 - val_acc: 0.9928\n",
      "Epoch 19/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0211 - acc: 0.9935 - val_loss: 0.0219 - val_acc: 0.9926\n",
      "Epoch 20/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0211 - acc: 0.9936 - val_loss: 0.0217 - val_acc: 0.9928\n",
      "Epoch 21/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0203 - acc: 0.9936 - val_loss: 0.0216 - val_acc: 0.9928\n",
      "Epoch 22/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0205 - acc: 0.9936 - val_loss: 0.0215 - val_acc: 0.9930\n",
      "Epoch 23/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0207 - acc: 0.9936 - val_loss: 0.0215 - val_acc: 0.9930\n",
      "Epoch 24/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0200 - acc: 0.9936 - val_loss: 0.0213 - val_acc: 0.9932\n",
      "Epoch 25/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0196 - acc: 0.9941 - val_loss: 0.0211 - val_acc: 0.9932\n",
      "Epoch 26/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0196 - acc: 0.9941 - val_loss: 0.0210 - val_acc: 0.9930\n",
      "Epoch 27/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0189 - acc: 0.9939 - val_loss: 0.0210 - val_acc: 0.9934\n",
      "Epoch 28/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0180 - acc: 0.9944 - val_loss: 0.0210 - val_acc: 0.9928\n",
      "Epoch 29/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0179 - acc: 0.9947 - val_loss: 0.0210 - val_acc: 0.9932\n",
      "Epoch 30/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0183 - acc: 0.9950 - val_loss: 0.0208 - val_acc: 0.9934\n",
      "Epoch 31/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0180 - acc: 0.9943 - val_loss: 0.0209 - val_acc: 0.9932\n",
      "Epoch 32/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0175 - acc: 0.9944 - val_loss: 0.0209 - val_acc: 0.9932\n",
      "Epoch 33/50\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.0169 - acc: 0.9945 - val_loss: 0.0208 - val_acc: 0.9932\n",
      "Epoch 34/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0179 - acc: 0.9944 - val_loss: 0.0208 - val_acc: 0.9934\n",
      "Epoch 35/50\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.0173 - acc: 0.9946 - val_loss: 0.0207 - val_acc: 0.9934\n",
      "Epoch 36/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0171 - acc: 0.9943 - val_loss: 0.0206 - val_acc: 0.9934\n",
      "Epoch 37/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0178 - acc: 0.9942 - val_loss: 0.0206 - val_acc: 0.9934\n",
      "Epoch 38/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0164 - acc: 0.9948 - val_loss: 0.0206 - val_acc: 0.9932\n",
      "Epoch 39/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0158 - acc: 0.9950 - val_loss: 0.0206 - val_acc: 0.9934\n",
      "Epoch 40/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0158 - acc: 0.9951 - val_loss: 0.0205 - val_acc: 0.9934\n",
      "Epoch 41/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0163 - acc: 0.9947 - val_loss: 0.0207 - val_acc: 0.9938\n",
      "Epoch 42/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0161 - acc: 0.9949 - val_loss: 0.0207 - val_acc: 0.9936\n",
      "Epoch 43/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0165 - acc: 0.9947 - val_loss: 0.0205 - val_acc: 0.9932\n",
      "Epoch 44/50\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.0162 - acc: 0.9947 - val_loss: 0.0204 - val_acc: 0.9932\n",
      "Epoch 45/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0160 - acc: 0.9946 - val_loss: 0.0205 - val_acc: 0.9932\n",
      "Epoch 46/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0166 - acc: 0.9944 - val_loss: 0.0205 - val_acc: 0.9932\n",
      "Epoch 47/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0150 - acc: 0.9950 - val_loss: 0.0205 - val_acc: 0.9932\n",
      "Epoch 48/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0175 - acc: 0.9944 - val_loss: 0.0207 - val_acc: 0.9936\n",
      "Epoch 49/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0150 - acc: 0.9952 - val_loss: 0.0206 - val_acc: 0.9936\n",
      "Epoch 50/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0159 - acc: 0.9951 - val_loss: 0.0208 - val_acc: 0.9938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "BATCH_SIZE = 100\n",
    "weight_path = base_dir + 'weights/2/' #save to drive\n",
    "\n",
    "train_pred_1 = np.zeros(train_df.shape[0])\n",
    "test_pred_1 = np.zeros(len(test_data))\n",
    "                       \n",
    "            \n",
    "name_weights_1 = os.path.join(weight_path,'best_model_1_weights.h5')\n",
    "callbacks = get_callbacks(name_weights_1,patience_lr=5)                  \n",
    "\n",
    "history = model.fit(train_X,train_y,\n",
    "                    epochs=50,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_data=(val_X, val_y),\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "model.load_weights(name_weights_1)  \n",
    "train_pred_1 = model.predict(train_data)\n",
    "test_pred_1 = model.predict(test_data)\n",
    "save_result(os.path.join(weight_path,'xcept_test.csv'),test_pred_1,'')\n",
    "save_result(os.path.join(weight_path,'xcept_train.csv'),train_pred_1,train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 852,
     "status": "ok",
     "timestamp": 1551963586736,
     "user": {
      "displayName": "qingqing mm",
      "photoUrl": "",
      "userId": "16115205609766247720"
     },
     "user_tz": -480
    },
    "id": "QR0H1amZOQ1X",
    "outputId": "76042981-f370-48e5-f823-bdf2b8bc5476"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1) (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_pred_1.shape,train_labels.shape)\n",
    "save_result(os.path.join(weight_path,'xcept_test.csv'),test_pred_1)\n",
    "save_result(os.path.join(weight_path,'xcept_train.csv'),train_pred_1,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XiIgEdSU8R2E"
   },
   "outputs": [],
   "source": [
    "train_data = np.load(open(incept_bottleneck_dir+'/train.npy','rb'))\n",
    "test_data = np.load(open(incept_bottleneck_dir+'/test.npy','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBJGcjC1hdVj"
   },
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(train_data,train_labels,test_size=0.2,random_state=43)\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "adam = optimizers.Adam(lr=0.0005, decay=1e-6)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1963
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33136,
     "status": "ok",
     "timestamp": 1551963635553,
     "user": {
      "displayName": "qingqing mm",
      "photoUrl": "",
      "userId": "16115205609766247720"
     },
     "user_tz": -480
    },
    "id": "7t1dNdTFznuI",
    "outputId": "88bc2378-b3c0-45bc-c0e2-df47d0548acd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.2704 - acc: 0.9073 - val_loss: 0.0855 - val_acc: 0.9880\n",
      "Epoch 2/50\n",
      "20000/20000 [==============================] - 1s 26us/step - loss: 0.0788 - acc: 0.9862 - val_loss: 0.0506 - val_acc: 0.9916\n",
      "Epoch 3/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0546 - acc: 0.9888 - val_loss: 0.0385 - val_acc: 0.9926\n",
      "Epoch 4/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0448 - acc: 0.9892 - val_loss: 0.0324 - val_acc: 0.9930\n",
      "Epoch 5/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0402 - acc: 0.9888 - val_loss: 0.0287 - val_acc: 0.9930\n",
      "Epoch 6/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0345 - acc: 0.9913 - val_loss: 0.0265 - val_acc: 0.9930\n",
      "Epoch 7/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0333 - acc: 0.9908 - val_loss: 0.0248 - val_acc: 0.9928\n",
      "Epoch 8/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0301 - acc: 0.9909 - val_loss: 0.0236 - val_acc: 0.9930\n",
      "Epoch 9/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0280 - acc: 0.9923 - val_loss: 0.0229 - val_acc: 0.9932\n",
      "Epoch 10/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0270 - acc: 0.9928 - val_loss: 0.0223 - val_acc: 0.9930\n",
      "Epoch 11/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0250 - acc: 0.9924 - val_loss: 0.0215 - val_acc: 0.9932\n",
      "Epoch 12/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0252 - acc: 0.9919 - val_loss: 0.0210 - val_acc: 0.9936\n",
      "Epoch 13/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0239 - acc: 0.9928 - val_loss: 0.0209 - val_acc: 0.9932\n",
      "Epoch 14/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0236 - acc: 0.9927 - val_loss: 0.0204 - val_acc: 0.9932\n",
      "Epoch 15/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0245 - acc: 0.9923 - val_loss: 0.0203 - val_acc: 0.9930\n",
      "Epoch 16/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0228 - acc: 0.9927 - val_loss: 0.0201 - val_acc: 0.9930\n",
      "Epoch 17/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0236 - acc: 0.9920 - val_loss: 0.0199 - val_acc: 0.9930\n",
      "Epoch 18/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0218 - acc: 0.9932 - val_loss: 0.0203 - val_acc: 0.9932\n",
      "Epoch 19/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0223 - acc: 0.9931 - val_loss: 0.0202 - val_acc: 0.9930\n",
      "Epoch 20/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0211 - acc: 0.9933 - val_loss: 0.0196 - val_acc: 0.9930\n",
      "Epoch 21/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0218 - acc: 0.9929 - val_loss: 0.0199 - val_acc: 0.9932\n",
      "Epoch 22/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0209 - acc: 0.9928 - val_loss: 0.0193 - val_acc: 0.9932\n",
      "Epoch 23/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0216 - acc: 0.9929 - val_loss: 0.0193 - val_acc: 0.9932\n",
      "Epoch 24/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0219 - acc: 0.9930 - val_loss: 0.0193 - val_acc: 0.9934\n",
      "Epoch 25/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0202 - acc: 0.9938 - val_loss: 0.0193 - val_acc: 0.9932\n",
      "Epoch 26/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0211 - acc: 0.9927 - val_loss: 0.0191 - val_acc: 0.9930\n",
      "Epoch 27/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0226 - acc: 0.9932 - val_loss: 0.0196 - val_acc: 0.9930\n",
      "Epoch 28/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0202 - acc: 0.9932 - val_loss: 0.0194 - val_acc: 0.9932\n",
      "Epoch 29/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0197 - acc: 0.9937 - val_loss: 0.0192 - val_acc: 0.9930\n",
      "Epoch 30/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0210 - acc: 0.9936 - val_loss: 0.0191 - val_acc: 0.9928\n",
      "Epoch 31/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0202 - acc: 0.9934 - val_loss: 0.0196 - val_acc: 0.9934\n",
      "Epoch 32/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0195 - acc: 0.9935 - val_loss: 0.0191 - val_acc: 0.9930\n",
      "Epoch 33/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0182 - acc: 0.9939 - val_loss: 0.0190 - val_acc: 0.9928\n",
      "Epoch 34/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0209 - acc: 0.9929 - val_loss: 0.0190 - val_acc: 0.9930\n",
      "Epoch 35/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0175 - acc: 0.9941 - val_loss: 0.0192 - val_acc: 0.9928\n",
      "Epoch 36/50\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.0206 - acc: 0.9934 - val_loss: 0.0190 - val_acc: 0.9932\n",
      "Epoch 37/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0188 - acc: 0.9936 - val_loss: 0.0199 - val_acc: 0.9932\n",
      "Epoch 38/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0191 - acc: 0.9938 - val_loss: 0.0192 - val_acc: 0.9932\n",
      "Epoch 39/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0197 - acc: 0.9936 - val_loss: 0.0193 - val_acc: 0.9934\n",
      "Epoch 40/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0191 - acc: 0.9946 - val_loss: 0.0189 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 41/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0188 - acc: 0.9944 - val_loss: 0.0190 - val_acc: 0.9928\n",
      "Epoch 42/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0192 - acc: 0.9941 - val_loss: 0.0189 - val_acc: 0.9928\n",
      "Epoch 43/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0177 - acc: 0.9941 - val_loss: 0.0190 - val_acc: 0.9930\n",
      "Epoch 44/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0181 - acc: 0.9941 - val_loss: 0.0189 - val_acc: 0.9928\n",
      "Epoch 45/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0187 - acc: 0.9937 - val_loss: 0.0189 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 5.000000237487257e-06.\n",
      "Epoch 46/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0196 - acc: 0.9936 - val_loss: 0.0189 - val_acc: 0.9928\n",
      "Epoch 47/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0185 - acc: 0.9941 - val_loss: 0.0189 - val_acc: 0.9928\n",
      "Epoch 48/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0189 - acc: 0.9940 - val_loss: 0.0189 - val_acc: 0.9928\n",
      "Epoch 49/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0191 - acc: 0.9937 - val_loss: 0.0189 - val_acc: 0.9928\n",
      "Epoch 50/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0187 - acc: 0.9937 - val_loss: 0.0189 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 5.000000328436726e-07.\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "train_pred_2 = np.zeros(train_df.shape[0])\n",
    "test_pred_2 = np.zeros(len(test_data))\n",
    "                       \n",
    "            \n",
    "name_weights_2 = os.path.join(weight_path,'best_model_2_weights.h5')\n",
    "callbacks = get_callbacks(name_weights_2,patience_lr=5)                  \n",
    "\n",
    "history = model.fit(train_X,train_y,\n",
    "                    epochs=50,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_data=(val_X, val_y),\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "model.load_weights(name_weights_2)    \n",
    "train_pred_2 = model.predict(train_data)\n",
    "test_pred_2 = model.predict(test_data)\n",
    "save_result(os.path.join(weight_path,'incept_test.csv'),test_pred_2)\n",
    "save_result(os.path.join(weight_path,'incept_train.csv'),train_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1835
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 143185,
     "status": "ok",
     "timestamp": 1551411533999,
     "user": {
      "displayName": "qingqing mm",
      "photoUrl": "",
      "userId": "16115205609766247720"
     },
     "user_tz": -480
    },
    "id": "MwejePUwgMOy",
    "outputId": "9b09b9f4-3cc3-4226-b4e9-f59574ab47f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9967897e-01]\n",
      " [9.9992663e-01]\n",
      " [9.9990332e-01]\n",
      " [9.9984229e-01]\n",
      " [5.7816505e-06]\n",
      " [2.3663044e-05]\n",
      " [6.0796738e-06]\n",
      " [1.6212463e-05]\n",
      " [5.0663948e-07]\n",
      " [7.3611736e-06]\n",
      " [1.6510487e-05]\n",
      " [9.9426293e-01]\n",
      " [3.4272671e-05]\n",
      " [2.2500753e-05]\n",
      " [2.1815300e-05]\n",
      " [2.9176474e-05]\n",
      " [9.8468924e-01]\n",
      " [9.9982381e-01]\n",
      " [1.3414025e-04]\n",
      " [5.5286288e-04]\n",
      " [9.9954009e-01]\n",
      " [3.8313568e-03]\n",
      " [9.9908626e-01]\n",
      " [9.9888957e-01]\n",
      " [3.5762787e-06]\n",
      " [9.9897945e-01]\n",
      " [9.9945062e-01]\n",
      " [3.1888485e-06]\n",
      " [1.1670858e-02]\n",
      " [9.9576080e-01]\n",
      " [9.9980319e-01]\n",
      " [8.9118946e-01]\n",
      " [9.9990511e-01]\n",
      " [1.7583370e-06]\n",
      " [5.8412552e-06]\n",
      " [1.2409687e-04]\n",
      " [1.4662743e-05]\n",
      " [3.8743019e-06]\n",
      " [9.5781511e-01]\n",
      " [7.5399876e-06]\n",
      " [9.9637812e-01]\n",
      " [9.9936843e-01]\n",
      " [9.9939626e-01]\n",
      " [9.9852705e-01]\n",
      " [2.8848648e-05]\n",
      " [9.9994135e-01]\n",
      " [1.2218952e-05]\n",
      " [9.9973708e-01]\n",
      " [9.9847591e-01]\n",
      " [4.5299530e-06]]\n",
      "[[9.97825384e-01]\n",
      " [9.99914169e-01]\n",
      " [9.99450922e-01]\n",
      " [9.99280810e-01]\n",
      " [5.96046448e-07]\n",
      " [1.22487545e-05]\n",
      " [4.55975533e-06]\n",
      " [2.37524509e-05]\n",
      " [1.66893005e-06]\n",
      " [2.17556953e-06]\n",
      " [1.32620335e-05]\n",
      " [9.91477609e-01]\n",
      " [1.71065331e-05]\n",
      " [8.37147236e-05]\n",
      " [1.17421150e-05]\n",
      " [9.23871994e-07]\n",
      " [9.56470728e-01]\n",
      " [9.99957860e-01]\n",
      " [4.58955765e-06]\n",
      " [2.23517418e-06]\n",
      " [9.99965549e-01]\n",
      " [3.27825546e-07]\n",
      " [9.99631763e-01]\n",
      " [9.99162138e-01]\n",
      " [1.19209290e-07]\n",
      " [9.96277630e-01]\n",
      " [9.99894738e-01]\n",
      " [2.35438347e-06]\n",
      " [7.19997287e-03]\n",
      " [9.99489188e-01]\n",
      " [9.99960780e-01]\n",
      " [8.17621231e-01]\n",
      " [9.99851108e-01]\n",
      " [2.38418579e-07]\n",
      " [1.37090683e-06]\n",
      " [8.64267349e-07]\n",
      " [1.93983316e-04]\n",
      " [3.57627869e-06]\n",
      " [9.96041656e-01]\n",
      " [3.78489494e-06]\n",
      " [9.81915236e-01]\n",
      " [9.99966025e-01]\n",
      " [9.99919236e-01]\n",
      " [9.99854326e-01]\n",
      " [2.59280205e-06]\n",
      " [9.99109626e-01]\n",
      " [5.96046448e-08]\n",
      " [9.99533653e-01]\n",
      " [9.97236609e-01]\n",
      " [1.01029873e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(test_pred_1[:50])\n",
    "print(test_pred_2[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2652,
     "status": "ok",
     "timestamp": 1551963836884,
     "user": {
      "displayName": "qingqing mm",
      "photoUrl": "",
      "userId": "16115205609766247720"
     },
     "user_tz": -480
    },
    "id": "2rezlmynzpvX",
    "outputId": "0b084c90-20a1-4670-949f-c630a2fb4a3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's binary_logloss: 0.0179653\tvalid_1's binary_logloss: 0.0203525\n",
      "[400]\ttraining's binary_logloss: 0.00862777\tvalid_1's binary_logloss: 0.0122862\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.0081491\tvalid_1's binary_logloss: 0.0123015\n"
     ]
    }
   ],
   "source": [
    "# lgb for stacking\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "param = {'learning_rate': 0.02,\n",
    "         'max_depth': 7,\n",
    "         'n_estimators':500,\n",
    "         'num_leaves': 15,\n",
    "         'min_child_samples': 2,\n",
    "         'min_child_weight':0.01,\n",
    "         \"feature_fraction\": 1,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.4 ,\n",
    "         'reg_alpha': 0, \n",
    "         'reg_lambda': 1.1,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"bagging_seed\": 11,\n",
    "         'objective':'binary', # for multi softmax \n",
    "         \"metric\": 'binary_logloss', #multi_logloss for multi classification  \n",
    "         \"verbosity\": -1}\n",
    "\n",
    "train_stack = np.hstack([train_pred_1,train_pred_2])\n",
    "test_stack = np.hstack([test_pred_1, test_pred_2])\n",
    "\n",
    "predictions = np.zeros(len(test_data))\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_stack,train_df['label'].values, test_size=0.2, random_state=44)\n",
    "\n",
    "trn_data = lgb.Dataset(X_train, y_train)\n",
    "val_data = lgb.Dataset(X_val, y_val)\n",
    "\n",
    "num_round = 400\n",
    "clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 100) \n",
    "predictions = clf.predict(test_stack, num_iteration=clf.best_iteration)\n",
    "save_result(os.path.join(weight_path,'result.csv'),predictions)\n",
    "train_predictions = clf.predict(train_stack, num_iteration=clf.best_iteration)\n",
    "save_result(os.path.join(weight_path,'train_pred.csv'),train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FcZT_1Joml-"
   },
   "outputs": [],
   "source": [
    "predictions = predictions.clip(min=0.005, max=0.995)\n",
    "save_result(os.path.join(weight_path,'tune.csv'),predictions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dog_cat_planB.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
